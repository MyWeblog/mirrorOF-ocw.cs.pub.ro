    
    

<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="utf-8" />
  <title>ep:laboratoare:02</title>
<meta name="generator" content="DokuWiki"/>
<meta name="robots" content="index,follow"/>
<meta name="date" content="2016-11-02T10:35:34+0200"/>
<meta name="keywords" content="ep,laboratoare,02"/>
<link rel="search" type="application/opensearchdescription+xml" href="../../../../lib/exe/opensearch.php" title="CS Open CourseWare"/>
<link rel="start" href="../../../../../courses.1.html"/>
<link rel="alternate" type="application/rss+xml" title="Recent Changes" href="../../../../feed.php"/>
<link rel="alternate" type="application/rss+xml" title="Current Namespace" href="../../../../feed.php%3Fmode=list&amp;ns=ep:laboratoare"/>
<link rel="alternate" type="text/html" title="Plain HTML" href="02.html"/>
<link rel="canonical" href="../../../../ep/laboratoare/02.html"/>
<link rel="stylesheet" type="text/css" href="../../../../lib/exe/css.php%3Ft=arctic&amp;tseed=1476798676.css"/>
<script type="text/javascript">/*<![CDATA[*/var NS='ep:laboratoare';var JSINFO = {"id":"ep:laboratoare:02","namespace":"ep:laboratoare","isadmin":0,"isauth":0};
/*!]]>*/</script>
<script type="text/javascript" charset="utf-8" src="../../../../lib/exe/js.php%3Ftseed=1476798676"></script>
<script type="text/x-mathjax-config">/*<![CDATA[*/MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ["$","$"], ["\\(","\\)"] ],
        displayMath: [ ["$$","$$"], ["\\[","\\]"] ],
        processEscapes: true
    }
});
/*!]]>*/</script>
<script type="text/javascript" charset="utf-8" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
<script type="text/javascript">/*<![CDATA[*/
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
		  
/*!]]>*/</script>
<script type="text/javascript">/*<![CDATA[*/
var pageTracker = _gat._getTracker("UA-38383934-1");
pageTracker._initData();
pageTracker._trackPageview();
		  
/*!]]>*/</script>
</head>
<body>
<div class="dokuwiki export">
<!-- TOC START -->
<div id="dw__toc">
<h3 class="toggle">Table of Contents</h3>
<div>

<ul class="toc">
<li class="level1"><div class="li"><a href="02.html#tutorial_02">Tutorial 02</a></div>
<ul class="toc">
<li class="level2"><div class="li"><a href="02.html#tutorial_objectives">00 Tutorial objectives</a></div></li>
<li class="level2"><div class="li"><a href="02.html#introducing_io_monitoring">01 Introducing I/O Monitoring</a></div>
<ul class="toc">
<li class="level3"><div class="li"><a href="02.html#reading_and_writing_data_-_memory_pages">Reading and Writing Data - Memory Pages</a></div></li>
<li class="level3"><div class="li"><a href="02.html#major_and_minor_page_faults">Major and Minor Page Faults</a></div></li>
<li class="level3"><div class="li"><a href="02.html#the_file_buffer_cache">The File Buffer Cache</a></div></li>
<li class="level3"><div class="li"><a href="02.html#types_of_memory_pages">Types of Memory Pages</a></div></li>
<li class="level3"><div class="li"><a href="02.html#writing_data_pages_back_to_disk">Writing Data Pages Back to Disk</a></div></li>
</ul>
</li>
<li class="level2"><div class="li"><a href="02.html#monitoring_io">02 Monitoring I/O</a></div>
<ul class="toc">
<li class="level3"><div class="li"><a href="02.html#calculating_ios_per_second">Calculating IOs Per Second</a></div></li>
<li class="level3"><div class="li"><a href="02.html#random_vs_sequential_io">Random vs Sequential I/O</a></div></li>
<li class="level3"><div class="li"><a href="02.html#when_virtual_memory_kills_io">When Virtual Memory Kills I/O</a></div></li>
<li class="level3"><div class="li"><a href="02.html#conclusion">Conclusion</a></div></li>
</ul>
</li>
<li class="level2"><div class="li"><a href="02.html#introducing_network_monitoring">03 Introducing Network Monitoring</a></div>
<ul class="toc">
<li class="level3"><div class="li"><a href="02.html#ethernet_configuration_settings">Ethernet Configuration Settings</a></div></li>
<li class="level3"><div class="li"><a href="02.html#monitoring_network_throughput">Monitoring Network Throughput</a></div>
<ul class="toc">
<li class="level4"><div class="li"><a href="02.html#using_iptraf_for_local_throughput">Using iptraf for Local Throughput</a></div></li>
<li class="level4"><div class="li"><a href="02.html#using_netperf_for_endpoint_throughput">Using netperf for Endpoint Throughput</a></div></li>
<li class="level4"><div class="li"><a href="02.html#using_iperf_to_measure_network_efficiency">Using iperf to Measure Network Efficiency</a></div></li>
</ul>
</li>
<li class="level3"><div class="li"><a href="02.html#individual_connections_with_tcptrace">Individual Connections with tcptrace</a></div></li>
<li class="level3"><div class="li"><a href="02.html#conclusion1">Conclusion</a></div></li>
</ul>
</li>
<li class="level2"><div class="li"><a href="02.html#exercices">Exercices</a></div>
<ul class="toc">
<li class="level3"><div class="li"><a href="02.html#ex00">Ex00</a></div></li>
<li class="level3"><div class="li"><a href="02.html#ex01">Ex01</a></div></li>
<li class="level3"><div class="li"><a href="02.html#ex02">Ex02</a></div></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<!-- TOC END -->

<h1 class="sectionedit1" id="tutorial_02">Tutorial 02</h1>
<div class="level1">

<p>
The material for this tutorial was taken from Darren Hoch’s “Linux System and Performance Monitoring”. You can access it at: <a href="http://ufsdump.org/papers/oscon2009-linux-monitoring.pdf" class="urlextern" title="http://ufsdump.org/papers/oscon2009-linux-monitoring.pdf"  rel="nofollow">http://ufsdump.org/papers/oscon2009-linux-monitoring.pdf</a>.
</p>

</div>
<!-- EDIT1 SECTION "Tutorial 02" [1-218] -->
<h2 class="sectionedit2" id="tutorial_objectives">00 Tutorial objectives</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Offer an introduction to I/O and Network monitoring.</div>
</li>
<li class="level1"><div class="li"> Get you acquainted with a few linux standard monitoring tools and their outputs, for monitoring the impact of the I/Os and Network on the system.</div>
</li>
</ul>

</div>
<!-- EDIT2 SECTION "00 Tutorial objectives" [219-462] -->
<h2 class="sectionedit3" id="introducing_io_monitoring">01 Introducing I/O Monitoring</h2>
<div class="level2">

<p>
Disk I/O subsystems are the slowest part of any Linux system. This is due mainly to their distance from the CPU and the fact that disks require the physics to work (rotation and seek). If the time taken to access disk as opposed to memory was converted into minutes and seconds, it is the difference between 7 days and 7 minutes. As a result, it is essential that the Linux kernel minimises the amount of I/O it generates on a disk. The following subsections describe the different ways the kernel processes data I/O from disk to memory and back.
</p>

</div>
<!-- EDIT3 SECTION "01 Introducing I/O Monitoring" [463-1053] -->
<h3 class="sectionedit4" id="reading_and_writing_data_-_memory_pages">Reading and Writing Data - Memory Pages</h3>
<div class="level3">

<p>
The Linux kernel breaks disk I/O into pages. The default page size on most Linux systems is 4K. It reads and writes disk blocks in and out of memory in 4K page sizes. You can check the page size of your system by using the time command in verbose mode and searching for the page size: <em># /usr/bin/time –v date</em>.
</p>

</div>
<!-- EDIT4 SECTION "Reading and Writing Data - Memory Pages" [1054-1421] -->
<h3 class="sectionedit5" id="major_and_minor_page_faults">Major and Minor Page Faults</h3>
<div class="level3">

<p>
Linux, like most UNIX systems, uses a virtual memory layer that maps into physical address space. This mapping is “on demand” in the sense that when a process starts, the kernel only maps what is required. When an application starts, the kernel searches the CPU caches and then physical memory. If the data does not exist in either, the kernel issues a major page fault (MPF). A MPF is a request to the disk subsystem to retrieve pages of the disk and buffer them in RAM.
</p>

<p>
Once memory pages are mapped into the buffer cache, the kernel will attempt to use these pages resulting in a minor page fault (MnPF). A MnPF saves the kernel time by reusing a page in memory as opposed to placing it back on the disk.
</p>

<p>
To find out how many MPF and MnPF occurred when an application starts, the time command can be used: <em># /usr/bin/time –v evolution</em>.
</p>

</div>
<!-- EDIT5 SECTION "Major and Minor Page Faults" [1422-2307] -->
<h3 class="sectionedit6" id="the_file_buffer_cache">The File Buffer Cache</h3>
<div class="level3">

<p>
The file buffer cache is used by the kernel to minimise MPFs and maximise MnPFs. As a system generates I/O over time, this buffer cache will continue to grow as the system  as the system will leave these pages in memory until memory gets low and the kernel needs to “free” some of these pages for other uses. The end result is that many system administrators see low amounts of free memory and become concerned when in reality, the system is just making good use of its caches.
</p>

</div>
<!-- EDIT6 SECTION "The File Buffer Cache" [2308-2819] -->
<h3 class="sectionedit7" id="types_of_memory_pages">Types of Memory Pages</h3>
<div class="level3">

<p>
There are 3 types of memory pages in the Linux kernel:
</p>
<ul>
<li class="level1"><div class="li"> Read Pages – Pages of data read in via disk (MPF) that are read only and backed on disk. These pages exist in the Buffer Cache and include static files, binaries, and libraries that do not change. The Kernel will continue to page these into memory as it needs them. If the system becomes short on memory, the kernel will “steal” these pages and place them back on the free list causing an application to have to MPF to bring them back in.</div>
</li>
<li class="level1"><div class="li"> Dirty Pages – Pages of data that have been modified by the kernel while in memory. These pages need to be synced back to disk at some point by the pdflush daemon. In the event of a memory shortage, kswapd (along with pdflush) will write these pages to disk in order to make room in memory.</div>
</li>
<li class="level1"><div class="li"> Anonymous Pages – Pages of data that do belong to a process, but do not have any file or backing store associated with them. They can&#039;t be synchronised back to disk. In the event of a memory shortage, kswapd writes these to the swap device as temporary storage until more RAM is free (“swapping” pages).</div>
</li>
</ul>

</div>
<!-- EDIT7 SECTION "Types of Memory Pages" [2820-3959] -->
<h3 class="sectionedit8" id="writing_data_pages_back_to_disk">Writing Data Pages Back to Disk</h3>
<div class="level3">

<p>
Applications themselves may choose to write dirty pages back to disk immediately using the fsync() or sync() system calls. These system calls issue a direct request to the I/O scheduler. If an application does not invoke these system calls, the pdflush kernel daemon runs at periodic intervals and writes pages back to disk.
</p>

</div>
<!-- EDIT8 SECTION "Writing Data Pages Back to Disk" [3960-4328] -->
<h2 class="sectionedit9" id="monitoring_io">02 Monitoring I/O</h2>
<div class="level2">

<p>
Certain conditions occur on a system that may create I/O bottlenecks. These conditions may be identified by using a standard set of system monitoring tools. These tools include <strong>top</strong>, <strong>vmstat</strong>, <strong>iostat</strong>, and <strong>sar</strong>. There are some similarities between the outputs of these commands, but for the most part, each offers a unique set of output that provides a different aspect on performance. The following subsections describe conditions that cause I/O bottlenecks.
</p>

</div>
<!-- EDIT9 SECTION "02 Monitoring I/O" [4329-4831] -->
<h3 class="sectionedit10" id="calculating_ios_per_second">Calculating IOs Per Second</h3>
<div class="level3">

<p>
Every I/O request to a disk takes a certain amount of time. This is due primarily to the fact that a disk must spin and a head must seek. The spinning of a disk is often referred to as “rotational delay” (RD) and the moving of the head as a “disk seek” (DS). The time it takes for each I/O request is calculated by adding DS and RD. A disk&#039;s RD is fixed based on the RPM of the drive. An RD is considered half a revolution around a disk. To calculate RD for a 10K RPM drive, perform the following:
</p>
<ol>
<li class="level1"><div class="li"> Divide 10000 RPM by 60 seconds (10000/60 = 166 RPS)</div>
</li>
<li class="level1"><div class="li"> Convert 1 of 166 to decimal (1/166 = 0.006 seconds per Rotation)</div>
</li>
<li class="level1"><div class="li"> Multiply the seconds per rotation by 1000 milliseconds (6 MS per rotation)</div>
</li>
<li class="level1"><div class="li"> Divide the total in half (6/2 = 3 MS) (RD is considered half a revolution around a disk)</div>
</li>
<li class="level1"><div class="li"> Add an average of 3 MS for seek time (3 MS + 3 MS = 6 MS)</div>
</li>
<li class="level1"><div class="li"> Add 2 MS for latency (internal transfer) (6 MS + 2 MS = 8MS)</div>
</li>
<li class="level1"><div class="li"> Divide 1000 MS by 8MS per I/O (1000/8 = 125 IOPS)</div>
</li>
</ol>

<p>
Each time an application issues an I/O, it takes an average of 8MS to service that I/O on a 10K RPM disk. Since this is a fixed time, it is imperative that the disk be as efficient as possible with the time it will spend reading and writing to the disk. The amount of I/O requests is often measured in I/Os Per Second (IOPS). The 10K RPM disk has the ability to push 120 to 150 (burst) IOPS. To measure the effectiveness of IOPS, divide the amount of IOPS by the amount of data read or written for each I/O.
</p>

<p>
<strong>Go through <span class="curid"><a href="../../../../ep/laboratoare/02.html#exercices" class="wikilink1" title="ep:laboratoare:02">Ex00</a></span></strong>
</p>

</div>
<!-- EDIT10 SECTION "Calculating IOs Per Second" [4832-6393] -->
<h3 class="sectionedit11" id="random_vs_sequential_io">Random vs Sequential I/O</h3>
<div class="level3">

<p>
The relevance of KB per I/O depends on the workload of the system. There are two different types of workload categories on a system: sequential and random.
</p>

<p>
Sequential I/O - The <strong>iostat</strong> command provides information on IOPS and the amount of data processed during each I/O. Use the <strong>–x</strong> switch with <strong>iostat</strong> (<em>iostat –x 1</em>). Sequential workloads require large amounts of data to be read sequentially and at once. These include applications such as enterprise databases executing large queries and streaming media services capturing data. With sequential workloads, the KB per I/O ratio should be high. Sequential workload performance relies on the ability to move large amounts of data as fast as possible. If each I/O costs time, it is imperative to get as much data out of that I/O as possible.
</p>

<p>
<strong>Go through <span class="curid"><a href="../../../../ep/laboratoare/02.html#exercices" class="wikilink1" title="ep:laboratoare:02">Ex01</a></span></strong>
</p>

<p>
Random I/O - Random access workloads do not depend as much on size of data. They depend primarily on the amount of IOPS a disk can push. Web and mail servers are examples of random access workloads. The I/O requests are rather small. Random access workload relies on how many requests can be processed at once. Therefore, the amount of IOPS the disk can push becomes crucial.
</p>

</div>
<!-- EDIT11 SECTION "Random vs Sequential I/O" [6394-7654] -->
<h3 class="sectionedit12" id="when_virtual_memory_kills_io">When Virtual Memory Kills I/O</h3>
<div class="level3">

<p>
If the system does not have enough RAM to accommodate all requests, it must start to use the SWAP device. As file system I/Os, writes to the SWAP device are just as costly. If the system is extremely deprived of RAM, it is possible that it will create a paging storm to the SWAP disk. If the SWAP device is on the same file system as the data trying to be accessed, the system will enter into contention for the I/O paths. This will cause a complete performance breakdown on the system. If pages can&#039;t be read or written to disk, they will stay in RAM longer. If they stay in RAM longer, the kernel will need to free the RAM. The problem is that the I/O channels are so clogged that nothing can be done. This inevitably leads to a kernel panic and crash of the system.
</p>

<p>
The following <strong>vmstat</strong> output demonstrates a system under memory distress. It is writing data out to the swap device:
</p>

<p>
<a href="../../../../_detail/ep/laboratoare/ep2_poz1.png%3Fid=ep%253Alaboratoare%253A02.html" class="media" title="ep:laboratoare:ep2_poz1.png"><img src="../../../../_media/ep/laboratoare/ep2_poz1.png%3Fw=550&amp;tok=b8c3e0" class="mediacenter" alt="" width="550" /></a>
</p>

<p>
The previous output demonstrates a large amount of read requests into memory (<strong>bi</strong>). The requests are so many that the system is short on memory (<strong>free</strong>). This is causing the system to send blocks to the swap device (<strong>so</strong>) and the size of swap keeps growing (<strong>swpd</strong>). Also notice a large percentage of WIO time (<strong>wa</strong>). This indicates that the CPU is starting to slow down because of I/O requests.
</p>

<p>
To see the effect the swapping to disk is having on the system, check the swap partition on the drive using <strong>iostat</strong>.
</p>

<p>
<a href="../../../../_detail/ep/laboratoare/ep2_poz2.png%3Fid=ep%253Alaboratoare%253A02.html" class="media" title="ep:laboratoare:ep2_poz2.png"><img src="../../../../_media/ep/laboratoare/ep2_poz2.png%3Fw=650&amp;tok=cfde03" class="mediacenter" alt="" width="650" /></a>
</p>

<p>
Both the swap device (<em>/dev/sda1</em>) and the file system device (<em>/dev/sda3</em>) are contending for I/O. Both have high amounts of write requests per second (<em>w/s</em>) and high wait time (<em>await</em>) to low service time ratios (<em>svctm</em>). This indicates that there is contention between the two partitions, causing both to underperform.
</p>

</div>
<!-- EDIT12 SECTION "When Virtual Memory Kills I/O" [7655-9533] -->
<h3 class="sectionedit13" id="conclusion">Conclusion</h3>
<div class="level3">

<p>
Takeaways for I/O monitoring:
</p>
<ul>
<li class="level1"><div class="li"> Any time the CPU is waiting on I/O, the disks are overloaded.</div>
</li>
<li class="level1"><div class="li"> Calculate the amount of IOPS your disks can sustain.</div>
</li>
<li class="level1"><div class="li"> Determine whether your applications require random or sequential disk access.</div>
</li>
<li class="level1"><div class="li"> Monitor slow disks by comparing wait times and service times.</div>
</li>
<li class="level1"><div class="li"> Monitor the swap and file system partitions to make sure that virtual memory is not contending for filesystem I/O.</div>
</li>
</ul>

</div>
<!-- EDIT13 SECTION "Conclusion" [9534-9976] -->
<h2 class="sectionedit14" id="introducing_network_monitoring">03 Introducing Network Monitoring</h2>
<div class="level2">

<p>
Out of all the subsystems to monitor, networking is the hardest to monitor. This is due primarily to the fact that the network is abstract. There are many factors that are beyond a system’s control when it comes to monitoring and performance. These factors include latency, collisions, congestion and packet corruption to name a few.
</p>

<p>
This section focuses on how to check the performance of Ethernet, IP and TCP. 
</p>

</div>
<!-- EDIT14 SECTION "03 Introducing Network Monitoring" [9977-10440] -->
<h3 class="sectionedit15" id="ethernet_configuration_settings">Ethernet Configuration Settings</h3>
<div class="level3">

<p>
Unless explicitly changed, all Ethernet networks are auto negotiated for speed. The benefit of this is largely historical when there were multiple devices on a network at different speeds and duplexes.
</p>

<p>
Most enterprise Ethernet networks run at either 100 or 1000BaseTX. Use <strong>ethtool</strong> to ensure that a specific system is synced at this speed.
</p>

<p>
In the following example, a system with a 100BaseTX card is running auto negotiated in 10BaseT.
</p>

<p>
<a href="../../../../_detail/ep/laboratoare/ep2_poz4.png%3Fid=ep%253Alaboratoare%253A02.html" class="media" title="ep:laboratoare:ep2_poz4.png"><img src="../../../../_media/ep/laboratoare/ep2_poz4.png%3Fw=450&amp;tok=700407" class="mediacenter" alt="" width="450" /></a>
</p>

<p>
The following command can be used to force the card into 100BaseTX: <em># ethtool -s eth0 speed 100 duplex full autoneg off</em>.
</p>

</div>
<!-- EDIT15 SECTION "Ethernet Configuration Settings" [10441-11092] -->
<h3 class="sectionedit16" id="monitoring_network_throughput">Monitoring Network Throughput</h3>
<div class="level3">

<p>
It is impossible to control or tune the switches, wires, and routers that sit in between two host systems. The best way to test network throughput is to send traffic between two systems and measure statistics like latency and speed.
</p>

</div>

<h4 id="using_iptraf_for_local_throughput">Using iptraf for Local Throughput</h4>
<div class="level4">

<p>
The <strong>iptraf</strong> utility (<a href="http://iptraf.seul.org" class="urlextern" title="http://iptraf.seul.org"  rel="nofollow">http://iptraf.seul.org</a>) provides a dashboard of throughput per Ethernet interface. (Use: <em># iptraf –d eth0</em>)
</p>

</div>

<h4 id="using_netperf_for_endpoint_throughput">Using netperf for Endpoint Throughput</h4>
<div class="level4">

<p>
Unlike <strong>iptraf</strong> which is a passive interface that monitors traffic, the <strong>netperf</strong> utility enables a system administrator to perform controlled tests of network throughput. This is extremely helpful in determining the throughput from a client workstation to a heavily utilised server such as a file or web server. The <strong>netperf</strong> utility runs in a client/server mode.
</p>

<p>
To perform a basic controlled throughput test, the <strong>netperf</strong> server must be running on the server system (<em>server# netserver</em>).
</p>

<p>
There are multiple tests that the <strong>netperf</strong> utility may perform. The most basic test is a standard throughput test. The following test initiated from the client performs a 30 second test of TCP based throughput on a <abbr title="Local Area Network">LAN</abbr>.
The output shows that that the throughput on the network is around 89 mbps. The server (192.168.1.215) is on the same <abbr title="Local Area Network">LAN</abbr>. This is exceptional performance for a 100 mbps network.
</p>

<p>
<a href="../../../../_detail/ep/laboratoare/ep2_poz5.png%3Fid=ep%253Alaboratoare%253A02.html" class="media" title="ep:laboratoare:ep2_poz5.png"><img src="../../../../_media/ep/laboratoare/ep2_poz5.png%3Fw=430&amp;tok=bc1b27" class="mediacenter" alt="" width="430" /></a>
</p>

<p>
Another useful test using <strong>netperf</strong> is to monitor the amount of TCP request and response transactions taking place per second. The test accomplishes this by creating a single TCP connection and then sending multiple request/response sequences over that connection (ack packets back and forth with a byte size of 1). This behavior is similar to applications such as RDBMS executing multiple transactions or mail servers piping multiple messages over one connection.
</p>

<p>
The following example simulates TCP request/response over the duration of 30 seconds.
</p>

<p>
<a href="../../../../_detail/ep/laboratoare/ep2_poz6.png%3Fid=ep%253Alaboratoare%253A02.html" class="media" title="ep:laboratoare:ep2_poz6.png"><img src="../../../../_media/ep/laboratoare/ep2_poz6.png%3Fw=450&amp;tok=664bd7" class="mediacenter" alt="" width="450" /></a>
</p>

<p>
In the previous output, the network supported a transaction rate of 4453 psh/ack per second using 1 byte payloads. This is somewhat unrealistic due to the fact that most requests, especially responses, are greater than 1 byte.
</p>

<p>
In a more realistic example, a <strong>netperf</strong> uses a default size of 2K for requests and 32K for responses.
</p>

<p>
<a href="../../../../_detail/ep/laboratoare/ep2_poz7.png%3Fid=ep%253Alaboratoare%253A02.html" class="media" title="ep:laboratoare:ep2_poz7.png"><img src="../../../../_media/ep/laboratoare/ep2_poz7.png%3Fw=470&amp;tok=04b945" class="mediacenter" alt="" width="470" /></a>
</p>

<p>
The transaction rate reduces significantly to 222 transactions per second.
</p>

</div>

<h4 id="using_iperf_to_measure_network_efficiency">Using iperf to Measure Network Efficiency</h4>
<div class="level4">

<p>
The <strong>iperf</strong> tool is similar to the <strong>netperf</strong> tool in that it checks connections between two endpoints. The difference with <strong>iperf</strong> is that it has more in-depth checks around TCP/UDP efficiency such as window sizes and QoS settings. The tool is designed for administrators who specifically want to tune TCP/IP stacks and then test the effectiveness of those stacks. The <strong>iperf</strong> tool is a single binary that can run in either server or client mode. The tool runs on port 5001 by default. In addition to TCP tests, <strong>iperf</strong> also has UDP tests to measure packet loss and jitter.
</p>

</div>
<!-- EDIT16 SECTION "Monitoring Network Throughput" [11093-14230] -->
<h3 class="sectionedit17" id="individual_connections_with_tcptrace">Individual Connections with tcptrace</h3>
<div class="level3">

<p>
The <strong>tcptrace</strong> utility provides detailed TCP based information about specific connections. The utility uses <strong>libpcap</strong> based files to perform an analysis of specific TCP sessions. The utility provides information that is at times difficult to catch in a TCP stream. This information includes:
</p>
<ul>
<li class="level1"><div class="li"> TCP Retransmissions – the amount of packets that needed to be sent again and the total data size</div>
</li>
<li class="level1"><div class="li"> TCP Window Sizes – identify slow connections with small window sizes</div>
</li>
<li class="level1"><div class="li"> Total throughput of the connection</div>
</li>
<li class="level1"><div class="li"> Connection duration</div>
</li>
</ul>

<p>
For more information refer to pages 34-37 from Darren Hoch’s “Linux System and Performance Monitoring” - <a href="http://ufsdump.org/papers/oscon2009-linux-monitoring.pdf" class="urlextern" title="http://ufsdump.org/papers/oscon2009-linux-monitoring.pdf"  rel="nofollow">http://ufsdump.org/papers/oscon2009-linux-monitoring.pdf</a>.
</p>

</div>
<!-- EDIT17 SECTION "Individual Connections with tcptrace" [14231-14987] -->
<h3 class="sectionedit18" id="conclusion1">Conclusion</h3>
<div class="level3">

<p>
Takeaways for network performance monitoring:
</p>
<ul>
<li class="level1"><div class="li"> Check to make sure all Ethernet interfaces are running at proper rates.</div>
</li>
<li class="level1"><div class="li"> Check total throughput per network interface and be sure it is inline with network speeds.</div>
</li>
<li class="level1"><div class="li"> Monitor network traffic types to ensure that the appropriate traffic has precedence on the system.</div>
</li>
</ul>

</div>
<!-- EDIT18 SECTION "Conclusion" [14988-15334] -->
<h2 class="sectionedit19" id="exercices">Exercices</h2>
<div class="level2">

</div>
<!-- EDIT19 SECTION "Exercices" [15335-15357] -->
<h3 class="sectionedit20" id="ex00">Ex00</h3>
<div class="level3">
<ul>
<li class="level1"><div class="li">   Calculate the rotational delay (RD) for a 5400 RPM drive</div>
</li>
</ul>

</div>
<!-- EDIT20 SECTION "Ex00" [15358-15437] -->
<h3 class="sectionedit21" id="ex01">Ex01</h3>
<div class="level3">
<ul>
<li class="level1"><div class="li"> Run <em>iostat –x 1 5</em></div>
</li>
<li class="level1"><div class="li"> Considering the last two outputs provided by the previous command, calculate the efficiency of IOPS for each of them. Does the amount of data written per I/O increase or decrease?</div>
</li>
</ul>

<p>
Hint
</p>
<ul>
<li class="level1"><div class="li"> Divide the kilobytes read (<em>rkB/s</em>) and written (<em>wkB/s</em>) per second by the reads per second (<em>r/s</em>) and the writes per second (<em>w/s</em>).</div>
</li>
</ul>

</div>
<!-- EDIT21 SECTION "Ex01" [15438-15820] -->
<h3 class="sectionedit22" id="ex02">Ex02</h3>
<div class="level3">
<ul>
<li class="level1"><div class="li"> Create a 16GB file of random generated integers ranging from 1 to 10 million.</div>
</li>
<li class="level1"><div class="li"> Write a script to sort the numbers in this file in ascending order.</div>
</li>
<li class="level1"><div class="li"> Monitor the system performance using the tools presented in this tutorial.</div>
</li>
</ul>

<p>
Hint
</p>
<ul>
<li class="level1"><div class="li"> Split the file into smaller chunks that would fit in memory (e.g. 4GB).</div>
</li>
<li class="level1"><div class="li"> Use a classical sort algorithm for sorting these chunks.</div>
</li>
<li class="level1"><div class="li"> Merge the sorted chunks two by two. Read in memory only two numbers at a time (one from each chunk) starting from the beginning, compare the numbers, write the smallest in the merged file, and read the next number from the chunk that had its number written in the merged file.</div>
</li>
<li class="level1"><div class="li"> Repeat the last step until you obtain the original file sorted.</div>
</li>
</ul>

</div>
<!-- EDIT22 SECTION "Ex02" [15821-] --></div>
</body>
</html>
